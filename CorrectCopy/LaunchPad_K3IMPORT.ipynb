{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAFETERIAI   ‚öôÔ∏è A Smart Cafe ‚öôÔ∏è\n",
    "AI CLUB \n",
    "\n",
    "ALPHARETTA HIGH SCHOOL\n",
    "\n",
    "üçèüçìüçáü•öü•ûüçóüçîüçüüçïüåÆüç£üç¶üç∞ü•õüç©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART -1 --> ALL INPUTES NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of sec that the food video is cut \n",
    "#1000 is 1 sec and 2000 is 2 sec\n",
    "numsec = 1000\n",
    "#face confidence is oppisite \n",
    "#0 is good and 100 is bad\n",
    "faceconfmin = 0\n",
    "faceconfmax = 100\n",
    "#resnet cutting image min prob percentage \n",
    "minimum_percentage_probability = 10\n",
    "#when detecting food if frequency is lower than x it gets deleted\n",
    "frequency_delete = 3\n",
    "#when deleteing food the probability limit it \n",
    "probability_limit = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 0\n",
    "Setup files and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install dfply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import psutil\n",
    "import random\n",
    "import datetime\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random\n",
    "import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import csv\n",
    "from dfply import *\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import date\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîú üîú üîú üìπ\n",
    "üßêü§îüßêü§îüßêü§îüßêü§î"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARE YOU HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "SETUP WEBCAM SOURCE 0 1 2?\n",
    "SETUP MAX WAIT TIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "SET LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folder to save video *new\n",
    "os.chdir('/Users/NidhiAneja/Documents/AI/Cafeteria/OpenCV-Python-Series-master/src_final/final_new_vids_in/')\n",
    "base_dir ='/Users/NidhiAneja/Documents/AI/Cafeteria/OpenCV-Python-Series-master/src_final/final_new_vids_in/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART A\n",
    "#CAPTURE VIDEO\n",
    "BREAK INTO FRAME\n",
    "#LOAD FILES IN A COMMON FOLDER UNTIL STUDENT IS IDENTIFIED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1. This function extracts images from video with 1 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_one_fps(video_source_path):\n",
    "    vidcap = cv2.VideoCapture(video_source_path)\n",
    "    count = 0\n",
    "    success = True\n",
    "    while success:\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC,(count*numsec)) # 2 second***   \n",
    "        success,image = vidcap.read()\n",
    "        ## Stop when last frame is identified\n",
    "        image_last = cv2.imread(\"frame{}.png\".format(count-1))\n",
    "        if np.array_equal(image, image_last):\n",
    "            break\n",
    "        cv2.imwrite(\"frame%d.png\" % count, image)     # save frame as PNG file\n",
    "        print( '{}.sec reading a new frame:{}'.format(count,success))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION FOR ROTATION\n",
    "#--------\n",
    "def rotate_image(image,deg):\n",
    "    if deg ==90:\n",
    "        return np.rot90(image)\n",
    "    if deg ==180:\n",
    "        return np.rot90(image,2)\n",
    "    if deg == 270:\n",
    "        return np.rot90(image,-1) #Reverse 90 deg rotation\n",
    "#--------  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "#printmd(\"<span style='color:blue'>Red text</span>\")\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "#printmd('**bold**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2. Name & Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_name = 'CAFETERIA' ## FIXED NAME AT THIS STAGE input()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  üõë ‚úã üõë ‚úã üõë ‚úã üõë ‚úã üõë ‚úã ü§Æ\n",
    "STOP HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A3.2 PRE-RECORDED VIDEOS CONVERTION\n",
    "(Option B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTO POPULATE FILE TYPE (mp4, avi, MOV etc.)\n",
    "x = os.listdir(os.path.join(base_dir, 'CAFETERIA'))\n",
    "matching = [s for s in x if \"CAFETERIA\" in s]\n",
    "filename, V_FORMAT = os.path.splitext(matching[0])\n",
    "print(\"V_FORMAT: \",V_FORMAT)\n",
    "#-----\n",
    "cap = cv2.VideoCapture(os.path.join(base_dir, student_name, \"CAFETERIA\" + V_FORMAT ) )\n",
    "video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "print(\"video length:\", video_length)\n",
    "#----\n",
    "os.chdir(os.path.join(os.path.join(base_dir,  student_name) ) )\n",
    "extract_image_one_fps('CAFETERIA'+ V_FORMAT)\n",
    "#----\n",
    "video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "try: \n",
    "    video_length > 96 \n",
    "    print(\"VIDEO SIZE \", video_length, \" FRAMES\")\n",
    "except ValueError:\n",
    "    print('Oops! That was an invalid recording. Check the webcam setting and try again')\n",
    "else:\n",
    "    print('Thank you.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A4. IDENTIFY PERSON\n",
    "openCV_faceRECOGNITION_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A4.a Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('/Users/NidhiAneja/Documents/AI/Cafeteria/OpenCV-Python-Series-master/src_final/cascades/data/haarcascade_frontalface_alt2.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Model (latest!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.read('/Users/NidhiAneja/Documents/AI/Cafeteria/OpenCV-Python-Series-master/src_final/recognizers/trainner.yml') # updated 0307\n",
    "labels = {}\n",
    "with open('/Users/NidhiAneja/Documents/AI/Cafeteria/OpenCV-Python-Series-master/src_final/pickles/labels.pickle', 'rb') as f:\n",
    "    og_labels = pickle.load(f)\n",
    "    labels = {v:k for k,v in og_labels.items()} \n",
    "print(og_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A4.b Read Video Recorded (or Loaded) earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(os.path.join(base_dir,  student_name) ) )\n",
    "os.path.join(os.path.join(base_dir,  student_name), student_name + '_face' + V_FORMAT ) \n",
    "feedback_vid = os.path.join(os.path.join(base_dir,  student_name), student_name + '_face' + V_FORMAT ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN VIDEO RECORDED EARLIER\n",
    "cap = cv2.VideoCapture(os.path.join(os.path.join(base_dir,  student_name), student_name + '_face' + V_FORMAT ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A4.c Identify Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "print(\"video_length:\",  video_length)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üö©üö©üö©\n",
    "ENSURE FOLLOWING SETTING ARE CORRECT!\n",
    "1. minimum CONFIDENCE  2. scaleFactor 3. minNeighbor 4. minSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CODE DOES NOT DO ROTATION\n",
    "PICK_NAMES = []\n",
    "frame_cnt = 0\n",
    "while(frame_cnt < video_length*.99):\n",
    "    ret, frame = cap.read()\n",
    "    try: \n",
    "        gray  = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(frame) #, scaleFactor=1.7, minNeighbors=5) #, minSize=(100, 100))\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]        \n",
    "            # recognizes\n",
    "            id_, conf = recognizer.predict(roi_gray) # give label id and confidence\n",
    "            #---- DEFINE PROBABILITY ----#\n",
    "            if conf >= faceconfmin and conf < faceconfmax:                \n",
    "                #print(labels[id_])\n",
    "                #print(conf)\n",
    "                print(labels[id_], round(conf,0) )\n",
    "                PICK_NAMES.append( [labels[id_], conf] ) # ****\n",
    "                #----\n",
    "                img_item = \"ExtractFaceFrame.png\"\n",
    "                cv2.imwrite(img_item, roi_gray)\n",
    "                #----\n",
    "                color = (255,0,0) # BGR 0-255\n",
    "                stroke = 2\n",
    "                end_cord_x = x+ w\n",
    "                end_cord_y = y + h\n",
    "                cv2.rectangle(frame, (x,y), (end_cord_x, end_cord_y), color, stroke)                \n",
    "        # Display the resulting frame \n",
    "        cv2.imshow('frame', frame)\n",
    "        frame_cnt += 1\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "    except ValueError:\n",
    "        print('Oops! Either the 1st or last frame invalid')\n",
    "    else:\n",
    "        print(frame_cnt)\n",
    "#----        # BREAK IF PICK_NAMES IS EMPTY\n",
    "if len(PICK_NAMES) ==0:\n",
    "    print(\"NO FACE SAMPLE COLLECTED! \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(PICK_NAMES) ==0:\n",
    "    print(\"NO FACE SAMPLE COLLECTED! \")\n",
    "else:\n",
    "    print(PICK_NAMES[:10])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A4.d Resolve Student Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for itm in PICK_NAMES:\n",
    "    teststring =[]\n",
    "    teststring.append(itm[0])\n",
    "    teststring.append(itm[1])\n",
    "    df = df.append([teststring])\n",
    "    \n",
    "df.columns = ['name','probability']\n",
    "#dftest = dftest.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.round(2) #***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['name', 'probability'], ascending= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.groupby('name')['probability'].median().reset_index()\n",
    "df1 = df1.sort_values(['probability'], ascending= True)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2= df.name.value_counts() # FREQUENCY\n",
    "df2 = pd.DataFrame(df2)\n",
    "df2.index.name = 'x'\n",
    "df2.reset_index(inplace=True)\n",
    "df2.columns = ['name', 'frequency']\n",
    "df2.head()\n",
    "#df2=df2.tail(-1)\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_face = pd.merge(df1, df2, on='name')\n",
    "#if 'pct' in final_face.columns: final_face.drop(columns='pct')\n",
    "#final_face.drop(columns='pct')\n",
    "#final_face.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABSOLUTE VALUE\n",
    "if any(df1[\"name\"] == df2[\"name\"].values[0]):\n",
    "    student_name = df2[\"name\"].values[0]\n",
    "    print('>> ', df2[\"name\"].values[0], \"<< \", \"identity confirmed!\", \n",
    "          \"face recognized\", df2['frequency'].values[0], \"times out of\", video_length, \"frames\" )\n",
    "else:\n",
    "    student_name = \"Student_not_identified\"\n",
    "    print('Resolve the Identity Conflict among >>', list(df2.name),  \"<<\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROPOTIONAL VALUES ****NEW\n",
    "df2[\"pct\"] = df2[\"frequency\"] / video_length\n",
    "print(df2[\"pct\"][0], \" percent of time faces was recognized for the highest contender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentid_conf = round(100* df2[\"frequency\"].values[0] / sum(df2[\"frequency\"]),0)\n",
    "print(studentid_conf, \"Calculated Confidence Level 100 is the highest level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_name # FINAL NAME TO GO FORWARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture outputface\n",
    "# ABSOLUTE VALUE\n",
    "#printmd(\"<span style='color:blue'>Red text</span>\")\n",
    "if any(df1[\"name\"] == df2[\"name\"].values[0]):\n",
    "    student_name = df2[\"name\"].values[0]\n",
    "    print('>> ', df2[\"name\"].values[0], \"<< \", \"identity confirmed!\", \n",
    "          \"face recognized\", df2['frequency'].values[0], \"times out of\", video_length, \"frames\" )\n",
    "else:\n",
    "    student_name = \"Student_not_identified\"\n",
    "    print('Resolve the Identity Conflict among >>', list(df2.name),  \"<<\")\n",
    "# PROPOTIONAL VALUES ****NEW\n",
    "print(\"----------------------------->\")\n",
    "df2[\"pct\"] = df2[\"frequency\"] / video_length\n",
    "print(df2[\"pct\"][0], \" percent of time faces was recognized for the highest contender\")\n",
    "studentid_conf = round(100* df2[\"frequency\"].values[0] / sum(df2[\"frequency\"]),0)\n",
    "print(\"----------------------------->\")\n",
    "print(studentid_conf, \"Calculated Confidence Level 100 is the highest level\")\n",
    "print(\"----------------------------->\")\n",
    "print(student_name) # FINAL NAME TO GO FORWARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEEDBACK LOOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTINUE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üõë ‚úã   üõë ‚úã    üõë ‚úã \n",
    "Confirm Identity by a Captured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if student_name == 'Student_not_identified':\n",
    "    #student_name=input(student_name) # FIXED FOR NOW üè¥üè≥Ô∏èüè¥\n",
    "    student_name=\"SOME_STUDENT\"\n",
    "print(student_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART B \n",
    "LaunchPad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE TIME ONLY\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/NidhiAneja/Documents/AI/Cafeteria/OpenCV-Python-Series-master/src_final/')\n",
    "from utils import CFEVideoConf, image_resize #currently stores in JUSTIN/src folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/NidhiAneja/Documents/AI/Cafeteria/OpenCV-Python-Series-master/src_final/final_ph_out/'\n",
    "video_in = '/Users/NidhiAneja/Documents/AI/Cafeteria/OpenCV-Python-Series-master/src_final/final_ph_out/in/'\n",
    "image_out = '/Users/NidhiAneja/Documents/AI/Cafeteria/OpenCV-Python-Series-master/src_final/final_ph_out/out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(base_dir, 'in') )\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B1. Move Files to Student Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVE AND RENAME THE FOLDER\n",
    "# ------------------------------\n",
    "shutil.move('/Users/NidhiAneja/Documents/AI/Cafeteria/OpenCV-Python-Series-master/src_final/final_new_vids_in/CAFETERIA', video_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = str(datetime.datetime.now())\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matching = [s for s in os.listdir(\".\") if student_name in s]\n",
    "nm_check = [s for s in os.listdir(\".\") if student_name == s]\n",
    "if nm_check == []:\n",
    "    os.rename('CAFETERIA', student_name)\n",
    "elif nm_check[0] == student_name:\n",
    "    os.rename(student_name, student_name + str(round(random.random(),2)) )\n",
    "    os.rename('CAFETERIA', student_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"\".join((str(student_name), V_FORMAT))\n",
    "video_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path =  os.path.join(base_dir, 'in', student_name, video_name )\n",
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART C\n",
    "IMAGEAI OBJECT SEPARATION\n",
    "IMAGEAI_OBECTION_DETECTION3_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "C0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Prediction import ImagePrediction \n",
    "from imageai.Detection import ObjectDetection\n",
    "detector = ObjectDetection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(base_dir, 'in', student_name) )\n",
    "execution_path = os.path.join(base_dir, 'in', student_name)\n",
    "execution_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C1. Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL option A\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath('/Users/NidhiAneja/Documents/AI/IMAGE_AI/ImageAI-master/MODELS/resnet50_coco_best_v2.0.1.h5')\n",
    "detector.loadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C2. Object Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "student_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_frames = os.listdir()\n",
    "lst_frames = sorted(lst_frames)\n",
    "# cleanup 1\n",
    "if '.DS_Store' in lst_frames: lst_frames.remove('.DS_Store')\n",
    "lst_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup 2 #zero bytes file\n",
    "for filename in os.listdir(os.path.join(video_in, student_name)):\n",
    "     if os.path.getsize(filename) == 0:\n",
    "            os.remove(filename) \n",
    "            print(\"File Removed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRAMES LIST UPDATED HERE FOR NEXT LOOP\n",
    "lst_frames=[]\n",
    "for filename in os.listdir(os.path.join(video_in, student_name)):\n",
    "    if filename.startswith(\"frame\"):\n",
    "        lst_frames.append(filename)\n",
    "lst_frames = sorted(lst_frames)\n",
    "#lst_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üö©üö©üö© \n",
    "CONFIRM THE PROBABILITY TO SPLIT THE PLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Custom Objects! 0311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = detector.CustomObjects(bottle = True, \n",
    "                                        cup = True,   #fork = True,   knife = True,   spoon = True,   bowl = True,   \n",
    "                                        banana = True,   \n",
    "                                        apple = True,   \n",
    "                                        sandwich = True,   \n",
    "                                        orange = True,\n",
    "                                        broccoli = True,   \n",
    "                                        carrot = True,     \n",
    "                                        pizza = True,   \n",
    "                                        donot = True,   \n",
    "                                        cake = True,\n",
    "                                        hot_dog = True,\n",
    "                                        bowl = True,\n",
    "                                        book = True)\n",
    "# hotdog = True,  cellphone  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lst_frames)\n",
    "for lst in lst_frames:\n",
    "    print(lst)\n",
    "    try:\n",
    "        detections = detector.detectCustomObjectsFromImage(custom_objects = custom_objects, \n",
    "                                           input_image= os.path.join( execution_path, lst),\n",
    "                                           output_image_path= lst[5] + str(random.randint(0,100)), \n",
    "                                           minimum_percentage_probability= minimum_percentage_probability,\n",
    "                                           extract_detected_objects=True)\n",
    "    except:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"PARSING IMAGES DONE!  \", lst)\n",
    "\n",
    "len(lst_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_folders = [x[0] for x in os.walk(execution_path)][1:] \n",
    "object_folders = sorted(object_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIVE RANDOM FILE NAMES BEFORE MOVING TO A SINGLE FOLDER\n",
    "i = 0\n",
    "for i in range(len(object_folders)):\n",
    "    path = object_folders[i]\n",
    "    #print(os.listdir(path))\n",
    "    for filename in os.listdir(path):\n",
    "        os.rename(path  + '/'+ filename, \n",
    "                  path  + '/captured'  +   str(random.randint(1,10001))  +'.jpg')\n",
    "        i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDENTIFY ZERO BYTES FILES AND REMOVE THOSE  # cleanup 2 #zero bytes file        \n",
    "REMOVE=0\n",
    "for j in range(len(object_folders)):\n",
    "    path = object_folders[j]\n",
    "    for filename in os.listdir(path):\n",
    "        if os.path.getsize(os.path.join(path, filename) ) < 20000:\n",
    "            os.remove(os.path.join(path, filename) )\n",
    "            REMOVE = +1\n",
    "print(REMOVE, \" Removed!\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDENTIFY ZERO BYTES FILES AND REMOVE THOSE  # cleanup 2 #zero bytes file        \n",
    "REMOVE=0\n",
    "for j in range(len(object_folders)):\n",
    "    path = object_folders[j]\n",
    "    for filename in os.listdir(path):\n",
    "        if os.path.getsize(os.path.join(path, filename) ) > 80000:\n",
    "            os.remove(os.path.join(path, filename) )\n",
    "            REMOVE = +1\n",
    "print(REMOVE, \" Removed!\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create objects folder to move all captured images in one folder\n",
    "if not any(os.listdir(execution_path)) == \"objects\":\n",
    "    os.mkdir(\"objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVE FILES FROM object-n folders to object folder\n",
    "for i in range(len(object_folders)):\n",
    "    object_files = os.listdir(object_folders[i])\n",
    "    if '.DS_Store' in object_files: object_files.remove('.DS_Store')\n",
    "    for f in object_files:\n",
    "        try:\n",
    "            shutil.move(os.path.join(object_folders[i], f), os.path.join(execution_path, \"objects\"))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART D: CUSTOM MODEL PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D1. Load Custom Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Prediction.Custom import ModelTraining\n",
    "from imageai.Prediction.Custom import CustomImagePrediction\n",
    "prediction = CustomImagePrediction()\n",
    "prediction.setModelTypeAsResNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üö©üö©üö© \n",
    "CONFIRM MODEL FOLDER & MODEL VERSION BELOW!\n",
    "CONFIRM NUMBER OF FOOD ITEMS!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_path='/Users/NidhiAneja/Documents/AI/IMAGE_AI/ImageAI-master/custom/'\n",
    "os.chdir(os.path.join(custom_model_path, \"models\"))\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*** 14 ITEMS *** 0303\n",
    "prediction.setModelPath('/Users/NidhiAneja/Documents/AI/IMAGE_AI/ImageAI-master/custom/models/model_ex-042_acc-0.985008.h5') \n",
    "prediction.setJsonPath('/Users/NidhiAneja/Documents/AI/IMAGE_AI/ImageAI-master/custom/json/model_class.json')\n",
    "#-----\n",
    "prediction.loadModel(num_objects=14) #updated 0303"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D2. Predict Food Items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_path = os.path.join(execution_path, \"objects\")\n",
    "all_files = os.listdir(detected_path)\n",
    "if '.DS_Store' in all_files: all_files.remove('.DS_Store')\n",
    "all_files[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_array = []\n",
    "for each_file in all_files:\n",
    "    if(each_file.endswith(\".jpg\") or each_file.endswith(\".png\")):\n",
    "        all_images_array.append(each_file)\n",
    "all_images_array[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(detected_path)\n",
    "#============================\n",
    "# *** RUN PREDICTIONS ***\n",
    "#============================\n",
    "results_array = prediction.predictMultipleImages(all_images_array, result_count_per_image=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D3. Summarize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = []\n",
    "for i in results_array:\n",
    "    FoodItem, prob = i[\"predictions\"], i[\"percentage_probabilities\"]\n",
    "    for idx in range(len(FoodItem)):\n",
    "        #print(pred[idx] , \" : \" , prob[idx])\n",
    "        save_results.append( (FoodItem[idx], prob[idx]) )\n",
    "    #print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(save_results, columns=['FoodItem','Probability'])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"image_name\"] = all_images_array\n",
    "df.Probability = pd.to_numeric(df.Probability, errors = 'coerce').fillna(0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ext = str(random.randint(1,100))\n",
    "df.to_csv(os.path.join(execution_path, \"save_results\" + file_ext  + \".csv\"), index=False, encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values([ 'FoodItem', 'Probability'], ascending= False)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itm_tags = dfx.FoodItem.value_counts()\n",
    "itm_tags = pd.DataFrame(itm_tags)\n",
    "itm_tags.index.name = 'x'\n",
    "itm_tags.reset_index(inplace=True)\n",
    "itm_tags.columns = ['FoodItem', 'frequency']\n",
    "itm_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FoodItem_excl_lst = []\n",
    "for excl_lst in itm_tags[(itm_tags['frequency'] <= frequency_delete)]['FoodItem']:\n",
    "    FoodItem_excl_lst.append(excl_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"deleting --->\")\n",
    "(FoodItem_excl_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df.Probability = pd.to_numeric(df.Probability, errors = 'coerce')\n",
    "df = df.sort_values(['Probability'], ascending = False)\n",
    "df = df.drop(df[df.Probability < probability_limit].index)\n",
    "print(len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates('FoodItem')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['FoodItem'].isin(FoodItem_excl_lst)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = str(datetime.datetime.now())\n",
    "#---\n",
    "df['dates'] = (now[:10])\n",
    "df['timestamp'] = (now[11:19])\n",
    "df['student_name'] = student_name\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D4. Price Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE TIME  ## ONLY 15 ITEMS ***\n",
    "# REF- food folders:: https://drive.google.com/open?id=1zSOhOZWVygKn08tctel-Xfwnjq_nlaYE \n",
    "ItemCostTable = {\"FoodItem\" : [\n",
    "    \"Cheerios\",\n",
    "    \"CheezIts\",\"Chips\",\"CinamonToastCrunch\",\n",
    "    \"FruitSnacks\", \"GoldenGrahamsBar\", \"GoldenGrahamsCereal\", \n",
    "    \"McNuggets\", \"MilkBlue\",\"MilkPurple\", \"NutriGrain\",\n",
    "    \"Pizza\", \"QuarterPounder\", \"RiceKrispes\"],\n",
    "                 \"Cost\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14]}\n",
    "CostTable = pd.DataFrame(ItemCostTable)          \n",
    "CostTable.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not number_of_classes  == len(CostTable):\n",
    "    print(\"! UPDATE PRICE TABLE !\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, CostTable, on=['FoodItem', 'FoodItem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['studentid_conf'] = studentid_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['file_extn'] = file_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D5. Save CSV File **FINAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(execution_path, \"final_safe_results\" + file_ext  + \".csv\"), \n",
    "          index=False, encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D6. VISUALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(video_in, student_name, \"objects\", df[\"image_name\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "**SHOW ONLY FINAL ITEMS DETECTED***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    im = cv2.imread(os.path.join(video_in, student_name, \"objects\", \n",
    "                                 df[\"image_name\"].iloc[i]))\n",
    "    im_resized = cv2.resize(im, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "    plt.imshow(cv2.cvtColor(im_resized, cv2.COLOR_BGR2RGB))\n",
    "    print(df[\"image_name\"].iloc[i])\n",
    "    print(df[\"FoodItem\"].iloc[i])\n",
    "    print(df[\"Probability\"].iloc[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "**SHOW ALL ITEMS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itm_tags = dfx.FoodItem.value_counts() # FREQUENCY\n",
    "itm_tags = pd.DataFrame(itm_tags)\n",
    "itm_tags.index.name = 'x'\n",
    "itm_tags.reset_index(inplace=True)\n",
    "itm_tags.columns = ['FoodItem', 'frequency']\n",
    "itm_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show everything\n",
    "for i in range(len(dfx)):\n",
    "    im = cv2.imread(os.path.join(video_in, student_name, \"objects\", \n",
    "                                 dfx[\"image_name\"].iloc[i]))\n",
    "    im_resized = cv2.resize(im, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "    plt.imshow(cv2.cvtColor(im_resized, cv2.COLOR_BGR2RGB))\n",
    "    print(dfx[\"image_name\"].iloc[i])\n",
    "    print(dfx[\"FoodItem\"].iloc[i])\n",
    "    print(dfx[\"Probability\"].iloc[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(video_in, student_name, \"objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(video_in, student_name, \"objects\"))\n",
    "capt_lst = os.listdir(\".\")\n",
    "if '.DS_Store' in capt_lst: capt_lst.remove('.DS_Store')\n",
    "len(capt_lst)\n",
    "for capt in capt_lst:\n",
    "    for d2 in dfx['FoodItem'][dfx['image_name'] == capt]:\n",
    "        os.rename(capt, d2+str(random.randint(1,10000)) + '.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART Z\n",
    "APPEND FOLDER w/ a random Number so same student can be re-entered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open('/Users/NidhiAneja/Documents/AI/Cafeteria/OpenCV-Python-Series-master/src_final/final_ph_out/CafeRecords.csv','w') as csvfile:\n",
    "    fieldnames = ['FoodItem', 'Probability', 'image_name', 'dates', 'timestamp', 'student_name', 'Cost', 'studentid_conf', 'file_extn']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/NidhiAneja/Documents/AI/Cafeteria/OpenCV-Python-Series-master/src_final/final_ph_out/CafeRecords.csv','a') as f:\n",
    "    f.write('\\n')\n",
    "    df.to_csv(f, header=False, index = False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENDING WITH ADDING DATE TO THE FOLDER\n",
    "now[:10]\n",
    "file_ext = str(random.randint(1,1000))\n",
    "os.rename(os.path.join(video_in, student_name ), \n",
    "          os.path.join(video_in, student_name + \"_\" + file_ext ) )  #str(now[:10]) ) )\n",
    "print(file_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  üõë ‚úã    üõë ‚úã    üõë ‚úã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CafeRecords = pd.read_csv('/Users/NidhiAneja/Documents/AI/Cafeteria/OpenCV-Python-Series-master/src_final/final_ph_out/CafeRecords.csv', error_bad_lines=False)\n",
    "CafeRecords['dates'] = pd.to_datetime(CafeRecords['dates']) \n",
    "CafeRecords.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Current_Spend = CafeRecords >> mask(X.student_name == student_name, X.dates == datetime.today().strftime('%Y-%m-%d')) >> group_by(X.student_name) >> summarize(Total_Spend = X.Cost.sum() )\n",
    "Current_Spend = CafeRecords >> mask(X.student_name == student_name, X.dates == date.today().strftime('%Y-%m-%d')) >> group_by(X.student_name) >> summarize(Total_Spend = X.Cost.sum() )\n",
    "if Current_Spend.empty:\n",
    "    Current_Spend  = pd.DataFrame(columns = [\"student_name\", \"Total_Spend\"])\n",
    "    Current_Spend=  {'student_name' : student_name, \"Total_Spend\" : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Current_Spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Semester_Spend = CafeRecords >> mask(X.student_name == student_name, X.dates > '2019-01-01') >> group_by(X.student_name) >> summarize(Total_Spend = X.Cost.sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_hist = CafeRecords >> mask(X.student_name == student_name) >> group_by(X.student_name, X.FoodItem) >> summarize(Semester_Count = n(X.FoodItem) )\n",
    "purchase_hist = list(zip(purchase_hist.FoodItem, purchase_hist.Semester_Count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('YOUR ACTIVITY SUMMARY WITH CAFE AI...')\n",
    "print(\"------------->\")\n",
    "print('STUDENT NAME == ', student_name)\n",
    "print(\"--------------->\")\n",
    "print('FACE RECOGINITION MODEL CONFIDENCE == %.lf' %(df['studentid_conf'][0]))\n",
    "print(\"----------------->\")\n",
    "print(\"YOU BOUGHT (Prob)\", list(zip(df.FoodItem,df.Probability)))\n",
    "print(\"------------------>\")\n",
    "#print('DOLLARS SPEND $', Current_Spend[1])\n",
    "print('TOTAL CHARGES TODAY == $%.lf' %(Current_Spend['Total_Spend'] ) )\n",
    "print(\"------------------->\")\n",
    "#print('CURRENT SEMESTER SPEND', Semester_Spend[1])\n",
    "print('TOTAL DEBIT THIS SEMESTER == $%.lf' %(Semester_Spend['Total_Spend'] ) )\n",
    "print(\"--------------------->\")\n",
    "print('YOUR PURCHASE IN THIS SEMSTER ',  purchase_hist)\n",
    "print(\"----------------------->\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
